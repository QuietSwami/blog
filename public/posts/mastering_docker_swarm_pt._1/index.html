<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Mastering Docker Swarm Pt.1 | Francisco Mendonca&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.
For this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability.">
<meta name="author" content="Francisco Mendonca">
<link rel="canonical" href="http://localhost:1313/posts/mastering_docker_swarm_pt._1/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/mastering_docker_swarm_pt._1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Mastering Docker Swarm Pt.1" />
<meta property="og:description" content="Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.
For this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/mastering_docker_swarm_pt._1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-06-17T11:56:50+02:00" />
<meta property="article:modified_time" content="2024-06-17T11:56:50+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Mastering Docker Swarm Pt.1"/>
<meta name="twitter:description" content="Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.
For this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Mastering Docker Swarm Pt.1",
      "item": "http://localhost:1313/posts/mastering_docker_swarm_pt._1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Mastering Docker Swarm Pt.1",
  "name": "Mastering Docker Swarm Pt.1",
  "description": "Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.\nFor this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability.\n",
  "keywords": [
    
  ],
  "articleBody": "Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.\nFor this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability.\nDNS-Based Discovery and Overlay Networks DNS-based service discovery is a fundamental feature of Docker Swarm that facilitates service-to-service communication. When you deploy a service in Docker Swarm, it automatically registers with the swarm’s internal DNS server. Each service is assigned a unique DNS name, which is accessible throughout the swarm cluster.\nThe internal DNS server in Docker Swarm manages the resolution of service names to their corresponding IP addresses. This allows containers to resolve service names to the IP addresses of the service’s tasks, enabling straightforward communication between services using DNS queries.\nDocker Swarm employs round-robin load balancing by default when multiple instances (tasks) of a service are running. When a service name is queried, the DNS server returns the IP addresses of all active tasks for that service. The Docker engine then balances incoming requests among these tasks, distributing the load evenly.\nEach service in a Docker Swarm can be accessed by its name. For example, if you deploy a service called web, other services can access it using the name web.\nExample First, we are going to create an Overlay network called my_network. This network will allow communication between containers deployed on different machines, enabling seamless service discovery and interaction across the swarm.\ndocker network create --driver overlay my_network --attachable Let’s inspect the network to verify its creation and configuration:\ndocker network inspect my_network [ { \"Name\": \"test_network\", \"Id\": \"j94uo2esqbrk0uy54c0xtq4dg\", \"Created\": \"2024-06-17T11:44:15.377226457Z\", \"Scope\": \"swarm\", \"Driver\": \"overlay\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"10.0.1.0/24\", \"Gateway\": \"10.0.1.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": null, \"Options\": { \"com.docker.network.driver.overlay.vxlanid_list\": \"4097\" }, \"Labels\": null } ] As you can see, there should be no peers nor any containers specified in the output. Peers are the nodes that are connected to the network, and they only connect once a service which uses the network is deployed on it.\nNext, we’ll deploy the first service, ensuring that we specify the network we want the service to be attached to:\ndocker service create --name web --replicas 3 --network my_network nginx Node: Docker automatically assigns DNS names for services. If you want to specify a custom DNS name, you can use the --dns-name flag. For example, --dns-name myweb will allow access via myweb.\nIn this example, we’ve created a service named web composed of 3 replicas running nginx. When this service is deployed, Docker Swarm automatically assigns DNS entries for it, allowing other services within the same network to resolve web to the IP addresses of its tasks.\nNow, to further test the DNS-Based Discovery, let’s run a busybox service, attach it to the same network, and then test the DNS resolution from within a container.\nNote: BusyBox is a lightweight, single executable that provides many common UNIX utilities, making it ideal for embedded systems and minimal environments. It combines tiny versions of many common commands, making it versatile and efficient for containerized environments.\ndocker service create --name app --replicas 3 --network my_network busybox:latest sleep 3600 Note: notice the sleep 3600. This will keep the busybox active for 1 hour. Without this command, the busybox starts and terminates immediately.\nWe can now check the status of the services to confirm they are running:\ndocker service ls Output:\nID NAME MODE REPLICAS IMAGE PORTS j94uo2esqbrk web replicated 3/3 nginx:latest k4t5u8w9x6y0 app replicated 3/3 busybox:latest To test the DNS resolution, we’ll access one of the busybox containers and attempt to ping the web service:\nIdentify a Running Container: First, SSH into a machine that is running the busybox container. You can find out which node is running the busybox containers by inspecting the tasks of the app service:\ndocker service ps app Access the container Once on the appropriate node, use docker exec to get a shell inside one of the busybox containers:\ndocker exec -it /bin/sh or:\ndocker exec -it $(docker ps -q --filter \"name=app\") /bin/sh Ping the web Service: Inside the container, use the ping command to test the DNS resolution of the web service:\nping web Output:\nPING web (10.0.1.2): 56 data bytes 64 bytes from 10.0.1.2: seq=0 ttl=64 time=0.045 ms 64 bytes from 10.0.1.3: seq=1 ttl=64 time=0.040 ms 64 bytes from 10.0.1.4: seq=2 ttl=64 time=0.042 ms This confirms that the web service is accessible by its DNS name web, and that the internal DNS server is correctly resolving the name to the IP addresses of the web service’s tasks. This DNS-based service discovery allows applications running inside the overlay network to communicate with each other seamlessly.\nIngress Load Balancing In Docker Swarm, the ingress load balancer distributes incoming network traffic across multiple service replicas, essential for scaling services and ensuring high availability.\nDocker Swarm uses an internal overlay network called the ingress network to handle incoming traffic. When a service is created with published ports, Docker Swarm automatically creates and manages the ingress network. This network spans all nodes in the swarm, enabling them to accept incoming traffic on the published ports.\nThe routing mesh is a critical component that routes incoming requests to any node in the Docker Swarm cluster, regardless of where the service tasks are running. The routing mesh ensures that traffic can reach the service even if its tasks are distributed across multiple nodes. This is achieved using IP Virtual Server (IPVS) for load balancing, which operates at the Linux kernel level to efficiently route traffic.\nPreviously, we’ve seen how to communicate between tasks in a swarm. Each node in the network keeps the DNS records of the overlay networks to which they belong. When a service is deployed, the internal DNS server updates all nodes with the necessary DNS records. This allows any node to resolve the service name to the appropriate virtual IP, ensuring that requests can be properly routed to available containers. The load balancing is performed in a round-robin fashion across healthy service instances.\nWhen a node receives a request for a published port, but the target container is not on that node, the routing mesh forwards the request to a node that is running the desired service instance. Since all nodes have a replica of the DNS records for the ingress network, they can efficiently redirect the traffic to the appropriate service instance.\n{{ $image := resources.Get “images/docker-ingress-network.jpg” }}\nBenefits of Docker’s Ingress Load Balancer Simplifies Traffic Management: Automatically handles incoming traffic and distributes it across service instances. No need for external load balancers for basic load balancing needs. High Availability: Ensures that traffic is distributed evenly, preventing any single instance from becoming a bottleneck. Supports failover by routing traffic to healthy instances if some go down. Scalability: Easily scale services up or down, and the ingress load balancer adjusts traffic distribution accordingly. Flexibility: Supports various deployment modes and configurations to suit different use cases. Limitations Basic Load Balancing: The built-in load balancer uses a simple round-robin algorithm, which may not be sufficient for more complex traffic management needs. Performance Overhead: The routing mesh introduces some performance overhead due to the additional network hops. Limited Customization: For more advanced routing and load balancing features, external tools like Traefik or NGINX might be required. ",
  "wordCount" : "1306",
  "inLanguage": "en",
  "datePublished": "2024-06-17T11:56:50+02:00",
  "dateModified": "2024-06-17T11:56:50+02:00",
  "author":{
    "@type": "Person",
    "name": "Francisco Mendonca"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/mastering_docker_swarm_pt._1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Francisco Mendonca's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Francisco Mendonca&#39;s Blog (Alt + H)">Francisco Mendonca&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Mastering Docker Swarm Pt.1
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2024-06-17 11:56:50 +0200 CEST'>June 17, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Francisco Mendonca

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#dns-based-discovery-and-overlay-networks" aria-label="DNS-Based Discovery and Overlay Networks">DNS-Based Discovery and Overlay Networks</a><ul>
                        
                <li>
                    <a href="#example" aria-label="Example">Example</a></li></ul>
                </li>
                <li>
                    <a href="#ingress-load-balancing" aria-label="Ingress Load Balancing">Ingress Load Balancing</a><ul>
                        
                <li>
                    <a href="#benefits-of-dockers-ingress-load-balancer" aria-label="Benefits of Docker&rsquo;s Ingress Load Balancer">Benefits of Docker&rsquo;s Ingress Load Balancer</a><ul>
                        
                <li>
                    <a href="#limitations" aria-label="Limitations">Limitations</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Docker Swarm integrates clustering seamlessly with Docker, connecting Docker Daemons into a single, unified network. In a Docker Swarm cluster, one (or more) node is designated as the master (or manager), while the rest are worker nodes. The master node is responsible for distributing services across the worker nodes and ensuring that the desired state of each service is maintained.</p>
<p>For this demonstration, I have created a Docker Swarm cluster on AWS, consisting of 3 master nodes and 3 worker nodes. This setup is designed to test High Availability within Docker Swarm. By having multiple master nodes, the cluster remains operational even if one master node fails, ensuring continuous service availability.</p>
<h2 id="dns-based-discovery-and-overlay-networks">DNS-Based Discovery and Overlay Networks<a hidden class="anchor" aria-hidden="true" href="#dns-based-discovery-and-overlay-networks">#</a></h2>
<p>DNS-based service discovery is a fundamental feature of Docker Swarm that facilitates service-to-service communication. When you deploy a service in Docker Swarm, it automatically registers with the swarm&rsquo;s internal DNS server. Each service is assigned a unique DNS name, which is accessible throughout the swarm cluster.</p>
<p>The internal DNS server in Docker Swarm manages the resolution of service names to their corresponding IP addresses. This allows containers to resolve service names to the IP addresses of the service&rsquo;s tasks, enabling straightforward communication between services using DNS queries.</p>
<p>Docker Swarm employs round-robin load balancing by default when multiple instances (tasks) of a service are running. When a service name is queried, the DNS server returns the IP addresses of all active tasks for that service. The Docker engine then balances incoming requests among these tasks, distributing the load evenly.</p>
<p>Each service in a Docker Swarm can be accessed by its name. For example, if you deploy a service called <code>web</code>, other services can access it using the name <code>web</code>.</p>
<h3 id="example">Example<a hidden class="anchor" aria-hidden="true" href="#example">#</a></h3>
<p>First, we are going to create an Overlay network called <code>my_network</code>. This network will allow communication between containers deployed on different machines, enabling seamless service discovery and interaction across the swarm.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker network create --driver overlay my_network --attachable
</span></span></code></pre></div><p>Let&rsquo;s inspect the network to verify its creation and configuration:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker network inspect my_network
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Name&#34;</span><span class="p">:</span> <span class="s2">&#34;test_network&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Id&#34;</span><span class="p">:</span> <span class="s2">&#34;j94uo2esqbrk0uy54c0xtq4dg&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Created&#34;</span><span class="p">:</span> <span class="s2">&#34;2024-06-17T11:44:15.377226457Z&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Scope&#34;</span><span class="p">:</span> <span class="s2">&#34;swarm&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Driver&#34;</span><span class="p">:</span> <span class="s2">&#34;overlay&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;EnableIPv6&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;IPAM&#34;</span><span class="p">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;Driver&#34;</span><span class="p">:</span> <span class="s2">&#34;default&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;Options&#34;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;Config&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="p">{</span>
</span></span><span class="line"><span class="cl">                    <span class="nt">&#34;Subnet&#34;</span><span class="p">:</span> <span class="s2">&#34;10.0.1.0/24&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="nt">&#34;Gateway&#34;</span><span class="p">:</span> <span class="s2">&#34;10.0.1.1&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="p">}</span>
</span></span><span class="line"><span class="cl">            <span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Internal&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Attachable&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Ingress&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;ConfigFrom&#34;</span><span class="p">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;Network&#34;</span><span class="p">:</span> <span class="s2">&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;ConfigOnly&#34;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Containers&#34;</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Options&#34;</span><span class="p">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="nt">&#34;com.docker.network.driver.overlay.vxlanid_list&#34;</span><span class="p">:</span> <span class="s2">&#34;4097&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="p">},</span>
</span></span><span class="line"><span class="cl">        <span class="nt">&#34;Labels&#34;</span><span class="p">:</span> <span class="kc">null</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">]</span>
</span></span></code></pre></div><p>As you can see, there should be no peers nor any containers specified in the output. Peers are the nodes that are connected to the network, and they only connect once a service which uses the network is deployed on it.</p>
<p>Next, we&rsquo;ll deploy the first service, ensuring that we specify the network we want the service to be attached to:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker service create --name web --replicas <span class="m">3</span> --network my_network nginx
</span></span></code></pre></div><blockquote>
<p>Node: Docker automatically assigns DNS names for services. If you want to specify a custom DNS name, you can use the <code>--dns-name</code> flag. For example, <code>--dns-name myweb</code> will allow access via <code>myweb</code>.</p>
</blockquote>
<p>In this example, we&rsquo;ve created a service named <code>web</code> composed of 3 replicas running nginx. When this service is deployed, Docker Swarm automatically assigns DNS entries for it, allowing other services within the same network to resolve web to the IP addresses of its tasks.</p>
<p>Now, to further test the DNS-Based Discovery, let&rsquo;s run a busybox service, attach it to the same network, and then test the DNS resolution from within a container.</p>
<blockquote>
<p>Note: BusyBox is a lightweight, single executable that provides many common UNIX utilities, making it ideal for embedded systems and minimal environments. It combines tiny versions of many common commands, making it versatile and efficient for containerized environments.</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker service create --name app --replicas <span class="m">3</span> --network my_network busybox:latest sleep <span class="m">3600</span>
</span></span></code></pre></div><blockquote>
<p>Note: notice the <code>sleep 3600</code>. This will keep the busybox active for 1 hour. Without this command, the busybox starts and terminates immediately.</p>
</blockquote>
<p>We can now check the status of the services to confirm they are running:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker service ls
</span></span></code></pre></div><p>Output:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ID            NAME      MODE        REPLICAS  IMAGE          PORTS
</span></span><span class="line"><span class="cl">j94uo2esqbrk  web       replicated  3/3       nginx:latest   
</span></span><span class="line"><span class="cl">k4t5u8w9x6y0  app       replicated  3/3       busybox:latest 
</span></span></code></pre></div><p>To test the DNS resolution, we&rsquo;ll access one of the busybox containers and attempt to ping the <code>web</code> service:</p>
<ol>
<li>
<p>Identify a Running Container:
First, SSH into a machine that is running the <code>busybox</code> container. You can find out which node is running the <code>busybox</code> containers by inspecting the tasks of the <code>app</code> service:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker service ps app
</span></span></code></pre></div></li>
<li>
<p>Access the container
Once on the appropriate node, use <code>docker exec</code> to get a shell inside one of the busybox containers:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker <span class="nb">exec</span> -it &lt;busybox-container-id&gt; /bin/sh
</span></span></code></pre></div><p>or:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker <span class="nb">exec</span> -it <span class="k">$(</span>docker ps -q --filter <span class="s2">&#34;name=app&#34;</span><span class="k">)</span> /bin/sh
</span></span></code></pre></div></li>
<li>
<p>Ping the <code>web</code> Service:
Inside the container, use the <code>ping</code> command to test the DNS resolution of the web service:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ping web
</span></span></code></pre></div></li>
</ol>
<p>Output:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">PING web <span class="o">(</span>10.0.1.2<span class="o">)</span>: <span class="m">56</span> data bytes
</span></span><span class="line"><span class="cl"><span class="m">64</span> bytes from 10.0.1.2: <span class="nv">seq</span><span class="o">=</span><span class="m">0</span> <span class="nv">ttl</span><span class="o">=</span><span class="m">64</span> <span class="nv">time</span><span class="o">=</span>0.045 ms
</span></span><span class="line"><span class="cl"><span class="m">64</span> bytes from 10.0.1.3: <span class="nv">seq</span><span class="o">=</span><span class="m">1</span> <span class="nv">ttl</span><span class="o">=</span><span class="m">64</span> <span class="nv">time</span><span class="o">=</span>0.040 ms
</span></span><span class="line"><span class="cl"><span class="m">64</span> bytes from 10.0.1.4: <span class="nv">seq</span><span class="o">=</span><span class="m">2</span> <span class="nv">ttl</span><span class="o">=</span><span class="m">64</span> <span class="nv">time</span><span class="o">=</span>0.042 ms
</span></span></code></pre></div><p>This confirms that the <code>web</code> service is accessible by its DNS name <code>web</code>, and that the internal DNS server is correctly resolving the name to the IP addresses of the <code>web</code> service&rsquo;s tasks. This DNS-based service discovery allows applications running inside the overlay network to communicate with each other seamlessly.</p>
<h2 id="ingress-load-balancing">Ingress Load Balancing<a hidden class="anchor" aria-hidden="true" href="#ingress-load-balancing">#</a></h2>
<p>In Docker Swarm, the ingress load balancer distributes incoming network traffic across multiple service replicas, essential for scaling services and ensuring high availability.</p>
<p>Docker Swarm uses an internal overlay network called the ingress network to handle incoming traffic. When a service is created with published ports, Docker Swarm automatically creates and manages the ingress network. This network spans all nodes in the swarm, enabling them to accept incoming traffic on the published ports.</p>
<p>The routing mesh is a critical component that routes incoming requests to any node in the Docker Swarm cluster, regardless of where the service tasks are running. The routing mesh ensures that traffic can reach the service even if its tasks are distributed across multiple nodes. This is achieved using IP Virtual Server (IPVS) for load balancing, which operates at the Linux kernel level to efficiently route traffic.</p>
<p>Previously, we&rsquo;ve seen how to communicate between tasks in a swarm. Each node in the network keeps the DNS records of the overlay networks to which they belong. When a service is deployed, the internal DNS server updates all nodes with the necessary DNS records. This allows any node to resolve the service name to the appropriate virtual IP, ensuring that requests can be properly routed to available containers. The load balancing is performed in a round-robin fashion across healthy service instances.</p>
<p>When a node receives a request for a published port, but the target container is not on that node, the routing mesh forwards the request to a node that is running the desired service instance. Since all nodes have a replica of the DNS records for the ingress network, they can efficiently redirect the traffic to the appropriate service instance.</p>
<p>{{ $image := resources.Get &ldquo;images/docker-ingress-network.jpg&rdquo; }}</p>
<h3 id="benefits-of-dockers-ingress-load-balancer">Benefits of Docker&rsquo;s Ingress Load Balancer<a hidden class="anchor" aria-hidden="true" href="#benefits-of-dockers-ingress-load-balancer">#</a></h3>
<ul>
<li>Simplifies Traffic Management:
<ul>
<li>Automatically handles incoming traffic and distributes it across service instances.</li>
<li>No need for external load balancers for basic load balancing needs.</li>
</ul>
</li>
<li>High Availability:
<ul>
<li>Ensures that traffic is distributed evenly, preventing any single instance from becoming a bottleneck.</li>
<li>Supports failover by routing traffic to healthy instances if some go down.</li>
</ul>
</li>
<li>Scalability:
<ul>
<li>Easily scale services up or down, and the ingress load balancer adjusts traffic distribution accordingly.</li>
</ul>
</li>
<li>Flexibility:
<ul>
<li>Supports various deployment modes and configurations to suit different use cases.</li>
</ul>
</li>
</ul>
<h4 id="limitations">Limitations<a hidden class="anchor" aria-hidden="true" href="#limitations">#</a></h4>
<ul>
<li>Basic Load Balancing:
<ul>
<li>The built-in load balancer uses a simple round-robin algorithm, which may not be sufficient for more complex traffic management needs.</li>
</ul>
</li>
<li>Performance Overhead:
<ul>
<li>The routing mesh introduces some performance overhead due to the additional network hops.</li>
</ul>
</li>
<li>Limited Customization:
<ul>
<li>For more advanced routing and load balancing features, external tools like Traefik or NGINX might be required.</li>
</ul>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/publishingdrafts/">
    <span class="title">« Prev</span>
    <br>
    <span>Publishing Drafts</span>
  </a>
  <a class="next" href="http://localhost:1313/posts/generators-and-iterators/">
    <span class="title">Next »</span>
    <br>
    <span>Generators and Iterators</span>
  </a>
</nav>

  </footer>
</article>


    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Francisco Mendonca&#39;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
